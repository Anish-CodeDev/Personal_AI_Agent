from typing import TypedDict,Sequence,Annotated
from dotenv import load_dotenv
from langgraph.graph import StateGraph,START,END
from langchain_core.messages import BaseMessage,SystemMessage,HumanMessage
from langchain_core.tools import tool
from langgraph.prebuilt import ToolNode
from langgraph.graph.message import add_messages
from langchain_google_genai import ChatGoogleGenerativeAI
from google import genai
import smtplib
import ssl
import imaplib
from gmail_api import get_gmail_service,read_subjects,move_email_to_spam,list_messages,get_subject,get_senders_addy
import requests
import tkinter as tk
from tkinter import filedialog
import asyncio
from mcp_client import main
from mcp_client_deep_think import deep_research
from mcp_client_autonomous_agent import autonomous_agent
load_dotenv()
client = genai.Client()
smtp_server = "smtp.gmail.com"
port = 587
context = ssl.create_default_context()
email_id = 'akanish327@gmail.com'
password = 'vvrw didd dabg uovh'
approval = True
mail = imaplib.IMAP4_SSL('imap.gmail.com')
mail.login(email_id,password)
mail.select('inbox')
service =get_gmail_service()
def select_file():
    root = tk.Tk()
    root.withdraw()
    file_path = filedialog.askopenfilename()
    root.destroy()

    return file_path
@tool
def send_email(subject:str,body:str,reciever_email:str):
    """This tool sends an email to the specified email address if provided with the subject and body, use a suitable subject for the email. Also if mentioned, use the name of the user."""
    if subject:

        message = f"Subject: {subject}\n\n{body}"
    else:
        message = f"{body}"
    
    print(message)
    inp = input("Is the email content good? Type Y for approving and N for rejecting the email \n")
    if inp == "Y":

        try:
            with smtplib.SMTP(smtp_server,port) as server:
                server.starttls(context=context)
                server.login(email_id,password)
                server.sendmail(email_id,reciever_email,message)
            
            return "The email was sent sucessfully"
        
        except Exception as e:
            return f"An error occured when sending an email, due to {str(e)}"
    
    else:
        print("I'm sorry for that")
        return f"The user did'nt like the email generated by me"

@tool
def read_emails(label:str):
    """This tool is used when the user want to view his/her emails, the user provides a folder in which you have to look into, if the user does'nt provide the label consider the label to be inbox"""
    print(label)
    subjects = read_subjects(service,label)
    return subjects

@tool
def move_emails_to_spam(label:str):
    """This tool cleanses or moves non important folders from the specified folder into spam folder, if the folder is not specified consider the folder to be inbox"""
    messages = list_messages(service,label)
    print(label)
    try:

        for msg in messages[:5]:
            subject = get_subject(service,msg['id'])

            #result = classify(subject,vocab,tokenizer,transformer)
            result = client.models.generate_content(
            model="gemini-2.5-flash-lite-preview-06-17",
            contents=f"""You have to classify the email subject enclosed within triple backticks as spam or not spam
            Email Subject: ```{subject}```
            Give the final result as spam or non-spam only
            """
            
            )
            result = result.text
            if result == 'spam':
                print("Invoked")
                move_email_to_spam(service,msg['id'],label)
        
        return "The relevant emails were moved to the spam folder"
    except Exception as e:
        print(str(e))
        return "The email could'nt be moved"

@tool
def respond_to_emails(label:str,name:str):
    """This tool is used when the user requests the agent to review the user's email and respond with relevant responses"""
    messages = list_messages(service,label)

    try:
        for msg in messages[:5]:
            subject = get_subject(service,msg['id'])
            reciever_email,reciever_name = get_senders_addy(service,msg['id'])
            new_subject = "Re: " + str(subject)
            llm_response = draft_llm.invoke([SystemMessage(content=f"Use all your talent to write an email which suits the user's requirements, do not ask the user for any additional information")] + [f'Generate a reply email using the context of the subject: {subject} by showing gratitude to the person who sent the email. Their name is {reciever_name}. The person sending this email is: {name}'])                
            response = send_email.invoke({"subject":'',"reciever_email":str(reciever_email),"body":dict(llm_response)['content']})
        return "I have responded to your emails with relevant responses"
    except Exception as e:
        print(str(e))
        return "An error occured when responding to your emails"

@tool
def query_rag(query:str):
    """This tool is used when the user refers to the spreadsheets, text documents or images uploaded by them.This tool is also used when the user has questions regarding already uploaded images. When the user asks for an explaination for an image use this tool."""
    print("Invoked")
    r = requests.get(f"http://127.0.0.1:5000/query/{str(query)}")
    if r.status_code == 200:
        return str(r.content)
    return "There was an error, while finding an answer to your query."
@tool
def maps(query:str):
    """This tool is used when the user has queries such as distance between two places"""
    return asyncio.run(main(query))

@tool
def research(message:str):
    """This tool is used when the user has queries regarding deep researching on a particular topic"""
    return asyncio.run(deep_research("I want to deep research on the topic: " + message))

@tool
def auto_agent(message:str):
    """This tool is used when the user wants to perform tasks like booking hotels,booking movie tickets"""
    print(message)
    return asyncio.run(autonomous_agent(message))

@tool
def upload_file():
    """This tool is used when the user want to upload their files from their computer"""
 

    file_path = select_file()
    print("Uploading your while, this might take a while")
    try:
        print(file_path)
        print("This might take a while")
        files = {"file":open(file_path,'rb')}
        response = requests.post("http://127.0.0.1:5000/upload/",files=files)
        if response.status_code == 200:
            return response.content
        return response.content
    except Exception as e:
        print(str(e))
        return "An error had occured when selecting the file:"
tools = [send_email,read_emails,move_emails_to_spam,respond_to_emails,query_rag,upload_file,maps,research,auto_agent]
llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite-preview-06-17').bind_tools(tools)
draft_llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash-lite-preview-06-17')
class AgentState(TypedDict):
    messages:Annotated[Sequence[BaseMessage],add_messages]

def agent(state:AgentState):
    instruction  =SystemMessage(content='You are my AI assistant, please answer my query to the best of your knowledge')
    response = llm.invoke([instruction] + state['messages'])
    return {"messages":[response]}

def should_continue(state:AgentState):
    if state['messages'][-1].tool_calls:
        return "continue"
    else:
        return "end"

graph = StateGraph(AgentState)
graph.add_node("agent",agent)
tool_node = ToolNode(tools=tools)
graph.add_node("tool_node",tool_node)

graph.add_edge(START,'agent')
graph.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue":"tool_node",
        "end":END
    }
)
graph.add_edge("tool_node","agent")
app = graph.compile()

user_input = input("User: ")
conversational_history = []

while user_input !='exit':
    conversational_history.append(HumanMessage(user_input))
    result = app.invoke({"messages":conversational_history})
    conversational_history = result['messages']
    print("AI: ",dict(conversational_history[-1])['content'])
    user_input = input("User: ")